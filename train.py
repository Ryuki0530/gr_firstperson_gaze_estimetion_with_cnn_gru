import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from datasets.gtea_loader import GTEADataset
from models.gaze_model import GazeEstimationModel
from tqdm import tqdm
import os
import argparse
import matplotlib.pyplot as plt  # â† å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

# å¼•æ•°å‡¦ç†
parser = argparse.ArgumentParser()
parser.add_argument('--epochs', type=int, default=100, help='Number of training epochs')
args = parser.parse_args()

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
BATCH_SIZE = 32
EPOCHS = args.epochs
LR = 1e-4
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
train_dataset = GTEADataset("data/processed/gtea/train_split.npz")
val_dataset   = GTEADataset("data/processed/gtea/val_split.npz")
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE)

# ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
model = GazeEstimationModel().to(DEVICE)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=LR)

# çŠ¶æ…‹è¡¨ç¤º
print(f"\n\nä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {DEVICE}")
print(f"å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°: {EPOCHS}")
print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {BATCH_SIZE}")

# å¯è¦–åŒ–ç”¨ãƒ­ã‚¹è¨˜éŒ²ãƒªã‚¹ãƒˆ
train_losses = []
val_losses = []

# æç”»ç”¨é–¢æ•°
def plot_losses(train_losses, val_losses, save_path="loss_plot.png"):
    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Val Loss')
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training and Validation Loss")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()

# å­¦ç¿’ãƒ«ãƒ¼ãƒ—
for epoch in range(EPOCHS):
    model.train()
    total_loss = 0

    print(f"\n[Epoch {epoch+1}/{EPOCHS}]")
    for batch_x, batch_y in tqdm(train_loader, desc="Training", leave=False):
        batch_x = batch_x.to(DEVICE)
        batch_y = batch_y.to(DEVICE)

        pred = model(batch_x)
        loss = criterion(pred, batch_y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * batch_x.size(0)

    avg_loss = total_loss / len(train_loader.dataset)

    # æ¤œè¨¼
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for batch_x, batch_y in tqdm(val_loader, desc="Validation", leave=False):
            batch_x = batch_x.to(DEVICE)
            batch_y = batch_y.to(DEVICE)

            pred = model(batch_x)
            loss = criterion(pred, batch_y)
            val_loss += loss.item() * batch_x.size(0)

    val_loss /= len(val_loader.dataset)

    train_losses.append(avg_loss)
    val_losses.append(val_loss)

    print(f"[Epoch {epoch+1}] Train Loss: {avg_loss:.4f} | Val Loss: {val_loss:.4f}")

    # æ¯ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ã‚°ãƒ©ãƒ•æ›´æ–°
    plot_losses(train_losses, val_losses)

# ãƒ¢ãƒ‡ãƒ«ä¿å­˜
os.makedirs("checkpoints", exist_ok=True)
torch.save(model.state_dict(), "checkpoints/gaze_estimation_model.pth")
print("âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: checkpoints/gaze_estimation_model.pth")

plt.ioff()
plot_losses(train_losses, val_losses)
print("ğŸ“ˆ ãƒ­ã‚¹æ›²ç·šã‚’ loss_plot.png ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
